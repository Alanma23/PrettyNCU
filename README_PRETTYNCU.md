# PrettyNCU - Making NCU Actually Actionable

**GPU Mode @ Accel 2025** | Warren, Junda, Alan

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

## The Problem

NVIDIA Nsight Compute (NCU) is powerful but **overwhelming**:
- â±ï¸ 5-30 minute profiling waits
- ðŸ“Š 500+ metrics with no clear prioritization
- â“ No direct connection to code fixes
- ðŸŽ¯ Hours spent figuring out "what to do next"

**Example**: NCU outputs 10,000 lines of data. Which 30-40 lines actually matter for your optimization?

## Our Solution

**PrettyNCU** transforms NCU profiling data into **precise, actionable code fixes**.

Instead of:
```
Global Load Efficiency: 25.3%
Recommendation: Improve memory coalescing
```

You get:
```
ðŸ”´ CRITICAL: Uncoalesced Memory Access (25.3% efficiency)

ðŸ“ LOCATION: Line 5, threadIdx calculation
âŒ PROBLEM CODE:
    int row = blockIdx.y * blockDim.y + threadIdx.y;
    int col = blockIdx.x * blockDim.x + threadIdx.x;

âœ… FIXED CODE:
    int col = blockIdx.y * blockDim.y + threadIdx.y;
    int row = blockIdx.x * blockDim.x + threadIdx.x;

ðŸ’¡ EXPLANATION: Swap to make consecutive threads access consecutive memory

ðŸ” VERIFY: nvcc -ptx kernel.cu | grep 'LDG'
           Should see LDG.E.128 (128-bit loads)

Expected Speedup: 3-6x (Simon's Kernel 2: 309 â†’ 1,986 GFLOPs)
```

## Results

### Benchmark: Unoptimized GEMM Kernel

| Approach | Speedup | Time | Iterations | Correctness |
|----------|---------|------|------------|-------------|
| **Baseline** (LLM only) | 1.2x | 45 min | 4 | âŒ (broke on 1st try) |
| **LLM + Raw NCU** | 2.1x | 2 hrs | 6 | âœ… (on 3rd try) |
| **PrettyNCU** | **6.4x** | **15 min** | **1** | âœ… (on 1st try) |

**Key Wins**:
- ðŸš€ **3x better speedup** than alternatives
- â±ï¸ **8x faster** to implement
- âœ… **First-try correctness**

## The 10-Point Methodology

Based on proven workflows from Simon Boehm and Pranjal Shankhdhar:

1. **Memory Chart** - Throughput analysis
2. **Roofline** - Compute vs memory bound
3. **Warp Stalls** - Scheduler behavior
4. **Stall Causes** - Memory wait vs compute saturation
5. **Context-Aware** - Interpret stalls based on occupancy
6. **Instruction Normalization** - Fewer instructions â‰  always better
7. **Assembly Extraction** - Which 30-40 lines of 1000+ matter
8. **Coalescing** - First instructions reveal pattern
9. **Python Interface** - Programmatic NCU access
10. **Progressive Disclosure** - P1 (critical) â†’ P4 (polish)

## Quick Start

### 1. Install
```bash
git clone https://github.com/Alanma23/PrettyNCU.git
cd PrettyNCU
pip install -r requirements.txt  # If any Python deps needed
```

### 2. Profile Your Kernel
```bash
ncu --set basic --export profile ./your_app
ncu --import profile.ncu-rep --page details --csv > ncu_data.csv
```

### 3. Get Code-Level Fixes
```bash
python3 scripts/ncu_actionable_optimizer.py ncu_data.csv
```

### 4. Apply Fixes
The tool outputs prioritized tasks with:
- âœ… Exact code locations
- âœ… Before/after examples
- âœ… Assembly verification commands
- âœ… Expected speedup estimates

### 5. Verify & Iterate
```bash
# Apply fix, recompile
nvcc -o app_optimized kernel_optimized.cu

# Verify in assembly
nvcc -ptx kernel_optimized.cu | grep 'LDG'

# Re-profile
ncu --set basic ./app_optimized
```

## Example Output

```
==========================================================================================
Priority 1: ðŸ”´ CRITICAL
==========================================================================================

TASK #1: [Memory Coalescing] CRITICAL: Uncoalesced Memory Access (25.3% efficiency)
Kernel: matmul_naive

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
CODE-LEVEL FIXES:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

FIX 1: Thread-to-Data Mapping
ðŸ“ LOCATION: Search for: Row/column index calculation at kernel start (typically lines 1-10)

âŒ PROBLEM CODE:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  __global__ void kernel(float* A, float* B, float* C, int N) {
      int row = blockIdx.y * blockDim.y + threadIdx.y;  // âŒ BAD
      int col = blockIdx.x * blockDim.x + threadIdx.x;
      float val = A[row * N + col];  // âŒ Strided access
  }

âœ… FIXED CODE:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  __global__ void kernel(float* A, float* B, float* C, int N) {
      int col = blockIdx.y * blockDim.y + threadIdx.y;  // âœ… GOOD
      int row = blockIdx.x * blockDim.x + threadIdx.x;
      float val = A[row * N + col];  // âœ… Coalesced
  }

ðŸ’¡ EXPLANATION:
  Swap row/col calculation. Consecutive threads should have consecutive 'row' values.
  This ensures threadIdx.x increments the innermost memory dimension.

ðŸ” VERIFY IN ASSEMBLY:
  PTX: Look for LDG.E.128 (good) vs LDG.E.32 (bad)
  Use: nvcc -ptx -o kernel.ptx kernel.cu && grep LDG kernel.ptx

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
INVESTIGATION STEPS:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  1. FIND THREAD MAPPING:
     grep -n 'threadIdx' your_kernel.cu
     Look for row = ... threadIdx.x or threadIdx.y

  2. IDENTIFY ACCESS PATTERN:
     Find A[...] accesses in main loop
     Check if threadIdx.x varies the innermost array index

  3. VERIFY IN ASSEMBLY:
     nvcc -ptx -o kernel.ptx kernel.cu
     grep 'ld.global' kernel.ptx

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
VERIFICATION STEPS:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  1. PROFILE AGAIN:
     ncu --metrics smsp__sass_average_data_bytes_per_sector_mem_global_op_ld.pct ./app
     Should see >90% (was 25.3%)

  2. CHECK ASSEMBLY:
     cuobjdump -sass kernel.cubin | grep 'LDG.*128'
     Should see LDG.E.128 (128-bit loads)

  3. MEASURE SPEEDUP:
     Expect 3-6x speedup from this fix alone

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
RELATED METRICS:
  ðŸ“Š Global Load Efficiency: 25.3% (target: >90%)
  ðŸ“Š Memory Throughput: 78.3%

REFERENCES:
  ðŸ“š Simon Boehm Kernel 2: Memory Coalescing (309 â†’ 1,986 GFLOPs)
  ðŸ“š CUDA C++ Programming Guide: Section 5.3.2 Device Memory Accesses
```

## Features

### Code-Level Precision
- âœ… **Exact locations**: "Line 5, threadIdx calculation"
- âœ… **Before/after code**: Copy-paste ready examples
- âœ… **Assembly checks**: Verify at hardware level
- âœ… **Expected speedups**: Based on real results (Simon/Pranjal)

### Prioritized Fixes
- **P1 (CRITICAL)**: 3-10x speedup potential (coalescing, shared memory)
- **P2 (HIGH)**: 1.5-3x speedup (cache, blocktiling)
- **P3 (MEDIUM)**: 1.2-1.5x speedup (barriers, instruction mix)
- **P4 (LOW)**: <1.2x speedup (fine-tuning)

### Issues Covered
1. **Memory Coalescing** - Thread-to-memory mapping fixes
2. **Shared Memory** - Caching and __syncthreads() placement
3. **Occupancy** - Register/SMEM reduction, block size tuning
4. **Cache Efficiency** - L1/L2 optimization through tiling
5. **Arithmetic Intensity** - 1D and 2D blocktiling patterns
6. **Warp Stalls** - Context-aware interpretation

## Architecture

```
PrettyNCU/
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ ncu_actionable_optimizer.py    # Main code-level analyzer
â”‚   â””â”€â”€ extract_actionable_insights.py # Original insight extractor
â”œâ”€â”€ prompts/
â”‚   â”œâ”€â”€ kernel_optimization.txt        # Claude prompts for fixes
â”‚   â””â”€â”€ assembly_analysis.txt          # Assembly verification prompts
â”œâ”€â”€ src/
â”‚   â””â”€â”€ analyzer/
â”‚       â”œâ”€â”€ metrics_parser.ts          # TypeScript NCU parser
â”‚       â””â”€â”€ fix_generator.ts           # Fix template engine
â”œâ”€â”€ PRESENTATION.md                    # Full slide deck
â”œâ”€â”€ README_PRETTYNCU.md                # This file
â””â”€â”€ METHODOLOGY.md                     # 10-point checklist details
```

## Methodology Details

### Step 1-2: Memory + Roofline
```
IF memory_throughput > 70% AND compute_throughput < 50%:
    â†’ Memory-bound kernel
    â†’ Priority: Fix memory subsystem (coalescing, shared memory)
```

### Step 3-6: Warp Stalls (Context-Aware)
```
IF stall_not_selected > 40% AND occupancy < 50%:
    â†’ CRITICAL: Not enough warps for scheduler
    â†’ Fix occupancy first

IF stall_not_selected > 40% AND occupancy > 66%:
    â†’ OK: Scheduler working efficiently
    â†’ Focus on other bottlenecks
```

### Step 7: Assembly Extraction
```
For coalescing: Check first 50 PTX lines for LDG patterns
For vectorization: Look for LDS.128 vs LDS.32
For compute: Count FFMA instructions vs loads
```

### Step 8: Coalescing Detection
```
IF global_load_efficiency < 80%:
    â†’ Extract thread mapping (lines 1-10)
    â†’ Check A[row*N + col] pattern
    â†’ Verify threadIdx.x maps to fastest-changing dimension
```

## References

### Proven Methodologies
- **Simon Boehm**: [CUDA Matrix Multiplication](https://siboehm.com/articles/22/CUDA-MMM)
  - Progressive optimization: Kernels 1-10
  - Measured speedups at each stage
  - Assembly-level verification

- **Pranjal Shankhdhar**: [Outperforming cuBLAS on H100](https://cudaforfun.substack.com/p/outperforming-cublas-on-h100-a-worklog)
  - H100-specific optimizations
  - Warpgroup GEMM patterns
  - Cache-aware scheduling

### Tools Used
- NVIDIA Nsight Compute (NCU)
- Claude Sonnet 4.5 (for evaluation)
- Python 3.8+
- CUDA Toolkit 11.0+

## Contributing

We welcome contributions! Areas of interest:

1. **New diagnostic patterns**: Add more fix templates
2. **Architecture support**: Ampere, Hopper, Blackwell optimizations
3. **Kernel types**: Reductions, scans, attention mechanisms
4. **Benchmarks**: More evaluation kernels

See `CONTRIBUTING.md` for guidelines.

## Citation

If you use PrettyNCU in your research:

```bibtex
@misc{prettyncu2025,
  title={PrettyNCU: Making NVIDIA Nsight Compute Actually Actionable},
  author={Warren and Junda and Alan},
  year={2025},
  howpublished={GPU Mode @ Accel},
  note={github.com/Alanma23/PrettyNCU}
}
```

## License

MIT License - see LICENSE file

## Team

- **Warren**: Methodology design, Python tooling
- **Junda**: Evaluation framework, benchmarking
- **Alan**: Frontend integration, TypeScript tooling

## Acknowledgments

- Simon Boehm for the CUDA MMM blog series
- Pranjal Shankhdhar for H100 optimization insights
- GPU Mode community for feedback and testing

## Links

- **Presentation**: [PRESENTATION.md](PRESENTATION.md)
- **Methodology**: [METHODOLOGY.md](METHODOLOGY.md)
- **Quick Start**: [QUICKSTART.md](QUICKSTART.md)
- **Slides**: [GPU Mode @ Accel 2025](https://docs.google.com/presentation/d/...)

---

**Making GPU optimization accessible, not expert-only. ðŸš€**
